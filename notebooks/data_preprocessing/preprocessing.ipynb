{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "698e82cc",
   "metadata": {},
   "source": [
    "<h2 style=\"text-align:center;\">Data Preprocessing</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6213d3a",
   "metadata": {},
   "source": [
    "1. [Handling Datetime Features](#date-time)\n",
    "2. [Handling Name Column](#handle-names)\n",
    "3. [Handling Negative Values](#negative-values)\n",
    "4. [Handling Missing Values](#missing-values)\n",
    "5. [Encoding](#encoding)\n",
    "6. [Feature Engineering](#feature-engineering)\n",
    "7. [Scaling](#scaling)\n",
    "8. [Preprocessing Pipeling](#pipeline)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72119768",
   "metadata": {},
   "source": [
    "<h2>Imports</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "33bac194",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec831925",
   "metadata": {},
   "source": [
    "<h2>Loading Dataset</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "0beff5e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting project root: c:\\Users\\HP\\Desktop\\Healthcare_test_results_classification-\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Detect project root by going up until we find the 'src' directory\n",
    "current_dir = os.getcwd()\n",
    "while not os.path.isdir(os.path.join(current_dir, 'src')):\n",
    "    current_dir = os.path.dirname(current_dir)\n",
    "    if current_dir == os.path.dirname(current_dir):  # Reached filesystem root\n",
    "        raise FileNotFoundError(\"Could not find 'src' directory in any parent folders.\")\n",
    "\n",
    "# Set project root and add it to sys.path\n",
    "PROJECT_ROOT = current_dir\n",
    "print(f\"Setting project root: {PROJECT_ROOT}\")\n",
    "os.chdir(PROJECT_ROOT)\n",
    "sys.path.insert(0, PROJECT_ROOT)\n",
    "\n",
    "\n",
    "from src.data import loader, preprocessor\n",
    "from src.visualization import exploration_visualized\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "cd31d10b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Name</th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Blood Type</th>\n",
       "      <th>Medical Condition</th>\n",
       "      <th>Date of Admission</th>\n",
       "      <th>Doctor</th>\n",
       "      <th>Hospital</th>\n",
       "      <th>Insurance Provider</th>\n",
       "      <th>Billing Amount</th>\n",
       "      <th>Room Number</th>\n",
       "      <th>Admission Type</th>\n",
       "      <th>Discharge Date</th>\n",
       "      <th>Medication</th>\n",
       "      <th>Test Results</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Bobby JacksOn</td>\n",
       "      <td>27</td>\n",
       "      <td>Female</td>\n",
       "      <td>O-</td>\n",
       "      <td>Asthma</td>\n",
       "      <td>06/06/2022</td>\n",
       "      <td>Mark Hartman Jr.</td>\n",
       "      <td>Sons and Miller</td>\n",
       "      <td>Cigna</td>\n",
       "      <td>2625.980554</td>\n",
       "      <td>379</td>\n",
       "      <td>Elective</td>\n",
       "      <td>18/08/2022</td>\n",
       "      <td>Ibuprofen</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>LesLie TErRy</td>\n",
       "      <td>68</td>\n",
       "      <td>Female</td>\n",
       "      <td>O-</td>\n",
       "      <td>Cancer</td>\n",
       "      <td>19/11/2021</td>\n",
       "      <td>Angela Contreras</td>\n",
       "      <td>White-White</td>\n",
       "      <td>Cigna</td>\n",
       "      <td>1471.387317</td>\n",
       "      <td>113</td>\n",
       "      <td>Elective</td>\n",
       "      <td>20/11/2021</td>\n",
       "      <td>Ibuprofen</td>\n",
       "      <td>Inconclusive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>DaNnY sMitH</td>\n",
       "      <td>21</td>\n",
       "      <td>Female</td>\n",
       "      <td>A+</td>\n",
       "      <td>Hypertension</td>\n",
       "      <td>05/03/2022</td>\n",
       "      <td>David Ruiz</td>\n",
       "      <td>Group Middleton</td>\n",
       "      <td>Medicare</td>\n",
       "      <td>5131.488104</td>\n",
       "      <td>154</td>\n",
       "      <td>Emergency</td>\n",
       "      <td>16/05/2022</td>\n",
       "      <td>Paracetamol</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>andrEw waTtS</td>\n",
       "      <td>91</td>\n",
       "      <td>Male</td>\n",
       "      <td>AB-</td>\n",
       "      <td>Diabetes</td>\n",
       "      <td>06/04/2020</td>\n",
       "      <td>Jenny Griffith</td>\n",
       "      <td>Morris-Arellano</td>\n",
       "      <td>Blue Cross</td>\n",
       "      <td>8972.793157</td>\n",
       "      <td>293</td>\n",
       "      <td>Urgent</td>\n",
       "      <td>26/04/2020</td>\n",
       "      <td>Ibuprofen</td>\n",
       "      <td>Abnormal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>adrIENNE bEll</td>\n",
       "      <td>52</td>\n",
       "      <td>Female</td>\n",
       "      <td>A+</td>\n",
       "      <td>Diabetes</td>\n",
       "      <td>31/12/2022</td>\n",
       "      <td>Cynthia Scott</td>\n",
       "      <td>Williams-Davis</td>\n",
       "      <td>Blue Cross</td>\n",
       "      <td>2015.522684</td>\n",
       "      <td>265</td>\n",
       "      <td>Emergency</td>\n",
       "      <td>11/02/2023</td>\n",
       "      <td>Penicillin</td>\n",
       "      <td>Abnormal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID           Name  Age  Gender Blood Type Medical Condition  \\\n",
       "0   1  Bobby JacksOn   27  Female         O-            Asthma   \n",
       "1   2   LesLie TErRy   68  Female         O-            Cancer   \n",
       "2   3    DaNnY sMitH   21  Female         A+      Hypertension   \n",
       "3   4   andrEw waTtS   91    Male        AB-          Diabetes   \n",
       "4   5  adrIENNE bEll   52  Female         A+          Diabetes   \n",
       "\n",
       "  Date of Admission            Doctor         Hospital Insurance Provider  \\\n",
       "0        06/06/2022  Mark Hartman Jr.  Sons and Miller              Cigna   \n",
       "1        19/11/2021  Angela Contreras      White-White              Cigna   \n",
       "2        05/03/2022        David Ruiz  Group Middleton           Medicare   \n",
       "3        06/04/2020    Jenny Griffith  Morris-Arellano         Blue Cross   \n",
       "4        31/12/2022     Cynthia Scott   Williams-Davis         Blue Cross   \n",
       "\n",
       "   Billing Amount  Room Number Admission Type Discharge Date   Medication  \\\n",
       "0     2625.980554          379       Elective     18/08/2022    Ibuprofen   \n",
       "1     1471.387317          113       Elective     20/11/2021    Ibuprofen   \n",
       "2     5131.488104          154      Emergency     16/05/2022  Paracetamol   \n",
       "3     8972.793157          293         Urgent     26/04/2020    Ibuprofen   \n",
       "4     2015.522684          265      Emergency     11/02/2023   Penicillin   \n",
       "\n",
       "   Test Results  \n",
       "0        Normal  \n",
       "1  Inconclusive  \n",
       "2        Normal  \n",
       "3      Abnormal  \n",
       "4      Abnormal  "
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "project_root = r\"C:\\Users\\HP\\Desktop\\Healthcare_test_results_classification-\"  # Replace with the actual path\n",
    "data_path = os.path.join(project_root, 'data', 'raw')\n",
    "\n",
    "train_df, test_df = loader.load_data(\n",
    "    train_path=os.path.join(data_path, 'train data.csv'),\n",
    "    test_path=os.path.join(data_path, 'test data.csv')\n",
    ")\n",
    "\n",
    "train_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f72543e",
   "metadata": {},
   "source": [
    "<h2 id=\"handled-names\">Handling Names Column</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76213a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "def cleaned_names(df, name_column):\n",
    "    \"\"\"\n",
    "    Clean messy names in a dataset column.\n",
    "    \"\"\"\n",
    "    for i in range(len(df)):\n",
    "        text = df.iloc[i][name_column]\n",
    "        \n",
    "        if pd.isna(text) or not str(text).strip():\n",
    "            df.iloc[i, df.columns.get_loc(name_column)] = \"\"\n",
    "            continue\n",
    "        \n",
    "        text = str(text).strip()\n",
    "        text = re.sub(r'\\s+', ' ', text)  # Remove extra spaces\n",
    "        \n",
    "        parts = []\n",
    "        for part in text.lower().split():\n",
    "            if '-' in part:\n",
    "                parts.append('-'.join(p.capitalize() for p in part.split('-')))\n",
    "            elif \"'\" in part and len(part.split(\"'\")) == 2:\n",
    "                p1, p2 = part.split(\"'\")\n",
    "                parts.append(p1.upper() + \"'\" + p2.capitalize())\n",
    "            else:\n",
    "                parts.append(part.capitalize())\n",
    "        \n",
    "        df.iloc[i, df.columns.get_loc(name_column)] = ' '.join(parts)\n",
    "    \n",
    "    print(f\"‚úÖ Names in column '{name_column}' have been cleaned and standardized.\")\n",
    "    return df\n",
    "\n",
    "# cleaned_df = cleaned_names(train_df, 'Name')\n",
    "# cleaned_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65df32b0",
   "metadata": {},
   "source": [
    "<h2 id=\"date-time\">Handling DateTime Datatype</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "b51d32f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìÖ Detected and converted date columns: ['Date of Admission', 'Discharge Date']\n"
     ]
    }
   ],
   "source": [
    "def handle_date_features(df):\n",
    "    df = df.copy()\n",
    "    date_like_columns = []\n",
    "\n",
    "    for col in df.columns:\n",
    "        if df[col].dtype == 'object':\n",
    "            try:\n",
    "                # Try parsing with known consistent format first\n",
    "                converted = pd.to_datetime(df[col], format=\"%d/%m/%Y\", errors='raise')\n",
    "                df[col] = pd.to_datetime(df[col], format=\"%d/%m/%Y\", errors='coerce')\n",
    "                date_like_columns.append(col)\n",
    "              \n",
    "            except Exception:\n",
    "                continue  # Not a consistently date-formatted column\n",
    "\n",
    "    if not date_like_columns:\n",
    "        print(\"‚ÑπÔ∏è No date-like columns were found and converted.\")\n",
    "    else:\n",
    "        print(f\"\\nüìÖ Detected and converted date columns: {date_like_columns}\")\n",
    "    \n",
    "    # print(\"\\nüìÑ Preview of dataset after date conversion:\")\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "fixed_datatypes=handle_date_features(train_df)\n",
    "# preprocessor.save_processed_df(fixed_datatypes,\"processed_train_data.csv\",output_dir=\"data/processed\")\n",
    "# fixed_datatypes.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4242be29",
   "metadata": {},
   "source": [
    "<h2 id=\"negative-values\">Handling Negative Values</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "1b550ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def check_negative_values(df):\n",
    "    numeric_cols = df.select_dtypes(include=['number']).columns\n",
    "    negative_counts = {}\n",
    "\n",
    "    for col in numeric_cols:\n",
    "        neg_count = (df[col] < 0).sum()\n",
    "        if neg_count > 0:\n",
    "            negative_counts[col] = neg_count\n",
    "    \n",
    "    if negative_counts:\n",
    "        print(\"\\nNegative values found in columns:\")\n",
    "        for col, count in negative_counts.items():\n",
    "            print(f\" - {col}: {count} negative values\")\n",
    "    else:\n",
    "        print(\"\\nNo negative values found in numerical columns.\")\n",
    "\n",
    "\n",
    "def replace_negatives_with_nan(df):\n",
    "    numeric_cols = df.select_dtypes(include=['number']).columns\n",
    "    \n",
    "    for col in numeric_cols:\n",
    "        df.loc[df[col] < 0, col] = pd.NA  # or use np.nan\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "# # Assume df is your DataFrame\n",
    "# check_negative_values(train_df)  # Check first\n",
    "\n",
    "# df = replace_negatives_with_nan(train_df)  # Replace negatives with NaN\n",
    "\n",
    "# check_negative_values(train_df)  # Check again to verify\n",
    "# df.to_csv('cleaned_dataset.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f630b2f6",
   "metadata": {},
   "source": [
    "<h2 id=\"missing-values\">Handling Missing Values</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "df14a903",
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_missing_values(df):\n",
    "  \n",
    "    filled_info = []\n",
    "\n",
    "    for col in df.columns:\n",
    "        if df[col].isnull().any():\n",
    "            if df[col].dtype in ['float64', 'int64']:\n",
    "                median_val = df[col].median()\n",
    "                df[col] = df[col].fillna(median_val)\n",
    "                filled_info.append(f\"Filled numerical column '{col}' with median: {median_val}\")\n",
    "            else:\n",
    "                mode_val = df[col].mode().dropna()\n",
    "                if not mode_val.empty:\n",
    "                    mode_val = mode_val[0]\n",
    "                    df[col] = df[col].fillna(mode_val)\n",
    "\n",
    "                    filled_info.append(f\"Filled categorical column '{col}' with mode: {mode_val}\")\n",
    "                else:\n",
    "                    filled_info.append(f\"Could not fill column '{col}' ‚Äî no valid mode found.\")\n",
    "\n",
    "    # Print summary\n",
    "    if filled_info:\n",
    "        print(\"\\n‚úÖMissing values handled:\\n\" + \"\\n\".join(filled_info))\n",
    "    else:\n",
    "        print(\"\\n‚ùåNo missing values found.\")\n",
    "\n",
    "    return df\n",
    "\n",
    "# handled_missing=handle_missing_values(fixed_datatypes)\n",
    "# preprocessor.save_processed_df(handled_missing,\"processed_train_data.csv\",output_dir=\"data/processed\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "352cd394",
   "metadata": {},
   "source": [
    "<h2 id=\"encoding\">Encoding</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "7298dbdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoding_features(df, max_unique_threshold=20):\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Drop irrelevant columns\n",
    "    drop_cols = ['ID', 'Name', 'Room Number']\n",
    "    df.drop(columns=[col for col in drop_cols if col in df.columns], inplace=True)\n",
    "    \n",
    "    # Convert datetime columns to numeric features\n",
    "    date_columns = df.select_dtypes(include=['datetime64']).columns\n",
    "    for date_col in date_columns:\n",
    "        # Convert to integer (days since epoch)\n",
    "        df[f'{date_col}_days'] = df[date_col].astype(np.int64) // 10**9 // 86400\n",
    "        # Drop original date column\n",
    "        df.drop(columns=[date_col], inplace=True)\n",
    "        print(f\"‚úÖ Converted '{date_col}' to integer days\")\n",
    "    \n",
    "    # Handle binary categorical column: Gender\n",
    "    if 'Gender' in df.columns:\n",
    "        df = pd.get_dummies(df, columns=['Gender'], drop_first=True)\n",
    "        print(\"‚úÖ One-hot encoded 'Gender'\")\n",
    "    \n",
    "    # Label encode target: Test Results (ordinal in context of classification)\n",
    "    if 'Test Results' in df.columns:\n",
    "        df['Test Results'] = df['Test Results'].map({\n",
    "            'Normal': 0, 'Abnormal': 1, 'Inconclusive': 2\n",
    "        })\n",
    "        print(\"üéØ Label encoded target column 'Test Results'\")\n",
    "    \n",
    "    # Detect categorical columns\n",
    "    categorical_cols = df.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "    categorical_cols = [col for col in categorical_cols if col != 'Test Results']\n",
    "    \n",
    "    # Separate based on cardinality\n",
    "    low_cardinality_cols = [col for col in categorical_cols if df[col].nunique() <= max_unique_threshold]\n",
    "    medium_cardinality_cols = [col for col in categorical_cols if max_unique_threshold < df[col].nunique() <= 50]\n",
    "    high_cardinality_cols = [col for col in categorical_cols if df[col].nunique() > 50]\n",
    "    \n",
    "    # One-hot encode low-cardinality columns\n",
    "    if low_cardinality_cols:\n",
    "        df = pd.get_dummies(df, columns=low_cardinality_cols, drop_first=True)\n",
    "        for col in low_cardinality_cols:\n",
    "            print(f\"‚úÖ One-hot encoded '{col}'\")\n",
    "    \n",
    "    # Target encoding for medium-cardinality columns (if target column exists)\n",
    "    if 'Test Results' in df.columns and medium_cardinality_cols:\n",
    "        for col in medium_cardinality_cols:\n",
    "            # Calculate mean of target for each category\n",
    "            encoding_map = df.groupby(col)['Test Results'].mean().to_dict()\n",
    "            new_col_name = f\"{col}_target_encoded\"\n",
    "            df[new_col_name] = df[col].map(encoding_map)\n",
    "            df.drop(columns=[col], inplace=True)\n",
    "            print(f\"‚úÖ Target encoded '{col}'\")\n",
    "    \n",
    "    # Frequency encoding for high-cardinality columns\n",
    "    for col in high_cardinality_cols:\n",
    "        freq_map = df[col].value_counts(normalize=True).to_dict()\n",
    "        new_col_name = f\"{col}_freq_encoded\"\n",
    "        df[new_col_name] = df[col].map(freq_map)\n",
    "        df.drop(columns=[col], inplace=True)\n",
    "        print(f\"‚úÖ Frequency encoded '{col}'\")\n",
    "    \n",
    "    print(f\"\\nüìê Encoded shape: {df.shape}\")\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "# encoded_df = encoding_features(train_df)\n",
    "# print(\"Encoded shape:\", encoded_df.shape)\n",
    "# encoded_df=preprocessor.encoding_features(handled_missing)\n",
    "\n",
    "# encoded_df = preprocessor.encoding_features(encoded_df)\n",
    "# preprocessor.save_processed_df(encoded_df, \"processed_train_data.csv\", output_dir=\"data/processed\")\n",
    "\n",
    "# encoded_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "256e063b",
   "metadata": {},
   "source": [
    "<h2 id=\"feature-engineering\">Feature Engineering</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "ee7d9c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_los(df, admission_col='Date of Admission', discharge_col='Discharge Date', \n",
    "                  dayfirst=True, verbose=True, drop_original=True):\n",
    "    \"\"\"\n",
    "    Calculate Length of Stay (LOS) in days between admission and discharge dates,\n",
    "    without fixing negative values. Optionally drops the original date columns.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Parse dates with error handling\n",
    "    df[admission_col] = pd.to_datetime(df[admission_col], dayfirst=dayfirst, errors='coerce')\n",
    "    df[discharge_col] = pd.to_datetime(df[discharge_col], dayfirst=dayfirst, errors='coerce')\n",
    "    \n",
    "    # Calculate LOS\n",
    "    df['LOS_days'] = (df[discharge_col] - df[admission_col]).dt.days\n",
    "    \n",
    "    if verbose:\n",
    "        # Show parsing success rate\n",
    "        n_missing = df['LOS_days'].isna().sum()\n",
    "        print(f\"Successfully parsed {len(df) - n_missing}/{len(df)} rows ({n_missing} failed)\")\n",
    "        \n",
    "        if n_missing < len(df):\n",
    "            print(\"\\nLOS statistics:\")\n",
    "            print(df['LOS_days'].describe())\n",
    "            \n",
    "            negative_count = (df['LOS_days'] < 0).sum()\n",
    "            if negative_count > 0:\n",
    "                print(f\"\\nNote: {negative_count} negative LOS values found.\")\n",
    "\n",
    "    # Drop original columns if specified\n",
    "    if drop_original:\n",
    "        df.drop(columns=[admission_col, discharge_col], inplace=True)\n",
    "    \n",
    " \n",
    "        \n",
    "    return df\n",
    "\n",
    "\n",
    "#calculate_los(fixed_datatypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5f73f2e",
   "metadata": {},
   "source": [
    "<h2 id=\"scaling\">Scaling (Standrization)</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d02ad17",
   "metadata": {},
   "source": [
    "\n",
    "PCA, Logistic Regression, SVM, MLP ‚Üí Use StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "30587a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_numerical_features(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = df.copy()\n",
    "\n",
    "    # Define known numerical features\n",
    "    numeric_cols = ['Age', 'Billing Amount']\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    df[numeric_cols] = scaler.fit_transform(df[numeric_cols])\n",
    "\n",
    "    print(f\"\\n‚úÖ Scaled numerical columns: {numeric_cols}\")\n",
    "    \n",
    "    print(f\"\\nüìê Scaled shape: {df.shape}\")\n",
    "    # print(f\"\\nüìÑ Preview of scaled dataset:\")\n",
    "\n",
    "    return df\n",
    "\n",
    "# scaled_df=scale_numerical_features(encoded_df)\n",
    "\n",
    "#  preprocessor.save_processed_df(scaled_df,\"processed_train_data.csv\",output_dir=\"data/processed\")\n",
    "#  scaled_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "874456a9",
   "metadata": {},
   "source": [
    "<h2 id=\"pipeline\">Preprocessing Pipeline</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "f23db7e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Names in column 'Name' have been cleaned and standardized.\n",
      "\n",
      "üìÖ Detected and converted date columns: ['Date of Admission', 'Discharge Date']\n",
      "Successfully parsed 50000/50000 rows (0 failed)\n",
      "\n",
      "LOS statistics:\n",
      "count    50000.000000\n",
      "mean        42.652000\n",
      "std         25.853069\n",
      "min         -1.000000\n",
      "25%         21.000000\n",
      "50%         42.000000\n",
      "75%         63.000000\n",
      "max        100.000000\n",
      "Name: LOS_days, dtype: float64\n",
      "\n",
      "Note: 203 negative LOS values found.\n",
      "\n",
      "Negative values found in columns:\n",
      " - Billing Amount: 247 negative values\n",
      " - LOS_days: 203 negative values\n",
      "\n",
      "‚úÖMissing values handled:\n",
      "Filled categorical column 'Blood Type' with mode: B-\n",
      "Filled categorical column 'Doctor' with mode: Angela Contreras\n",
      "Filled categorical column 'Hospital' with mode: Houston PLC\n",
      "Filled categorical column 'Insurance Provider' with mode: Blue Cross\n",
      "Filled numerical column 'Billing Amount' with median: 5340.178472\n",
      "Filled categorical column 'Admission Type' with mode: Urgent\n",
      "Filled numerical column 'LOS_days' with median: 42.0\n",
      "‚úÖ One-hot encoded 'Gender'\n",
      "üéØ Label encoded target column 'Test Results'\n",
      "‚úÖ One-hot encoded 'Blood Type'\n",
      "‚úÖ One-hot encoded 'Medical Condition'\n",
      "‚úÖ One-hot encoded 'Insurance Provider'\n",
      "‚úÖ One-hot encoded 'Admission Type'\n",
      "‚úÖ One-hot encoded 'Medication'\n",
      "‚úÖ Frequency encoded 'Doctor'\n",
      "‚úÖ Frequency encoded 'Hospital'\n",
      "\n",
      "üìê Encoded shape: (50000, 29)\n",
      "\n",
      "‚úÖ Scaled numerical columns: ['Age', 'Billing Amount']\n",
      "\n",
      "üìê Scaled shape: (50000, 29)\n",
      "‚úÖ Processed data saved to data/processed/processed_train_data.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Billing Amount</th>\n",
       "      <th>Test Results</th>\n",
       "      <th>LOS_days</th>\n",
       "      <th>Gender_Male</th>\n",
       "      <th>Blood Type_A-</th>\n",
       "      <th>Blood Type_AB+</th>\n",
       "      <th>Blood Type_AB-</th>\n",
       "      <th>Blood Type_B+</th>\n",
       "      <th>Blood Type_B-</th>\n",
       "      <th>...</th>\n",
       "      <th>Insurance Provider_Medicare</th>\n",
       "      <th>Insurance Provider_UnitedHealthcare</th>\n",
       "      <th>Admission Type_Emergency</th>\n",
       "      <th>Admission Type_Urgent</th>\n",
       "      <th>Medication_Ibuprofen</th>\n",
       "      <th>Medication_Lipitor</th>\n",
       "      <th>Medication_Paracetamol</th>\n",
       "      <th>Medication_Penicillin</th>\n",
       "      <th>Doctor_freq_encoded</th>\n",
       "      <th>Hospital_freq_encoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.772600</td>\n",
       "      <td>-0.877583</td>\n",
       "      <td>0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.01056</td>\n",
       "      <td>0.02700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.906636</td>\n",
       "      <td>-1.239534</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.02778</td>\n",
       "      <td>0.04216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.018342</td>\n",
       "      <td>-0.092137</td>\n",
       "      <td>0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.00698</td>\n",
       "      <td>0.03122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.848646</td>\n",
       "      <td>1.112066</td>\n",
       "      <td>1</td>\n",
       "      <td>20.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.00132</td>\n",
       "      <td>0.02846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.251324</td>\n",
       "      <td>-1.068955</td>\n",
       "      <td>1</td>\n",
       "      <td>42.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.00720</td>\n",
       "      <td>0.02700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Age  Billing Amount  Test Results  LOS_days  Gender_Male  \\\n",
       "0 -0.772600       -0.877583             0      73.0        False   \n",
       "1  0.906636       -1.239534             2       1.0        False   \n",
       "2 -1.018342       -0.092137             0      72.0        False   \n",
       "3  1.848646        1.112066             1      20.0         True   \n",
       "4  0.251324       -1.068955             1      42.0        False   \n",
       "\n",
       "   Blood Type_A-  Blood Type_AB+  Blood Type_AB-  Blood Type_B+  \\\n",
       "0          False           False           False          False   \n",
       "1          False           False           False          False   \n",
       "2          False           False           False          False   \n",
       "3          False           False            True          False   \n",
       "4          False           False           False          False   \n",
       "\n",
       "   Blood Type_B-  ...  Insurance Provider_Medicare  \\\n",
       "0          False  ...                        False   \n",
       "1          False  ...                        False   \n",
       "2          False  ...                         True   \n",
       "3          False  ...                        False   \n",
       "4          False  ...                        False   \n",
       "\n",
       "   Insurance Provider_UnitedHealthcare  Admission Type_Emergency  \\\n",
       "0                                False                     False   \n",
       "1                                False                     False   \n",
       "2                                False                      True   \n",
       "3                                False                     False   \n",
       "4                                False                      True   \n",
       "\n",
       "   Admission Type_Urgent  Medication_Ibuprofen  Medication_Lipitor  \\\n",
       "0                  False                  True               False   \n",
       "1                  False                  True               False   \n",
       "2                  False                 False               False   \n",
       "3                   True                  True               False   \n",
       "4                  False                 False               False   \n",
       "\n",
       "   Medication_Paracetamol  Medication_Penicillin  Doctor_freq_encoded  \\\n",
       "0                   False                  False              0.01056   \n",
       "1                   False                  False              0.02778   \n",
       "2                    True                  False              0.00698   \n",
       "3                   False                  False              0.00132   \n",
       "4                   False                   True              0.00720   \n",
       "\n",
       "   Hospital_freq_encoded  \n",
       "0                0.02700  \n",
       "1                0.04216  \n",
       "2                0.03122  \n",
       "3                0.02846  \n",
       "4                0.02700  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "def process_and_save_data(train_df, outputpath=\"data/processed/\"):\n",
    "    os.makedirs(outputpath, exist_ok=True)\n",
    "\n",
    "    # Step-by-step preprocessing\n",
    "    handeled_names= cleaned_names(train_df, 'Name')\n",
    "    handled_dates = handle_date_features(handeled_names)\n",
    "    engineered_los = calculate_los(handled_dates, admission_col='Date of Admission', discharge_col='Discharge Date')\n",
    "    check_negative_values(engineered_los)\n",
    "    handled_negatives = replace_negatives_with_nan(engineered_los)\n",
    "    handled_missing_values = handle_missing_values(handled_negatives)\n",
    "    encoded_data = encoding_features(handled_missing_values)\n",
    "    scaled_data = scale_numerical_features(encoded_data)\n",
    "\n",
    "    # Save and return\n",
    "    preprocessor.save_processed_df(scaled_data, \"processed_train_data.csv\", output_dir=outputpath)\n",
    "    print(f\"‚úÖ Processed data saved to {outputpath}processed_train_data.csv\")\n",
    "   \n",
    "    return scaled_data\n",
    "\n",
    "# Call it\n",
    "processed_train_df = process_and_save_data(train_df, outputpath=\"data/processed/\")\n",
    "processed_train_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e77aa44c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d4ddc0db",
   "metadata": {},
   "source": [
    "<h2>Old Pipeline</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "9fa1dd45",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# class DateFeatureHandler(BaseEstimator, TransformerMixin):\n",
    "#     def fit(self, X, y=None): return self\n",
    "#     def transform(self, X): return preprocessor.handle_date_features(X)\n",
    "\n",
    "# class MissingValueImputer(BaseEstimator, TransformerMixin):\n",
    "#     def fit(self, X, y=None): return self\n",
    "#     def transform(self, X): return preprocessor.handle_missing_values(X)\n",
    "\n",
    "# class FeatureEncoder(BaseEstimator, TransformerMixin):\n",
    "#     def fit(self, X, y=None): return self\n",
    "#     def transform(self, X): return preprocessor.encoding_features(X)\n",
    "\n",
    "\n",
    "# class FeatureScaler(BaseEstimator, TransformerMixin):\n",
    "#     def fit(self, X, y=None): return self\n",
    "#     def transform(self, X): return preprocessor.scale_numerical_features(X)\n",
    "\n",
    "\n",
    "# preprocessing_pipeline = Pipeline([\n",
    "#     ('imputer', MissingValueImputer()),\n",
    "#     ('date_handler', DateFeatureHandler()),\n",
    "#     ('encoder', FeatureEncoder()),\n",
    "#     ('scaler', FeatureScaler())\n",
    "# ])\n",
    "\n",
    "# processed_df = preprocessing_pipeline.fit_transform(train_df)\n",
    "\n",
    "# preprocessor.save_processed_df(processed_df, filename=\"preprocessed_train_data.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f09034d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7e6c6d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec0604e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14edf573",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54af7a96",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "842cbe35",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "027c0066",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
