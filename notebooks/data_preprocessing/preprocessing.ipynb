{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "698e82cc",
   "metadata": {},
   "source": [
    "<h2 style=\"text-align:center;\">Data Preprocessing</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72119768",
   "metadata": {},
   "source": [
    "<h2>Imports</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "33bac194",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec831925",
   "metadata": {},
   "source": [
    "<h2>🔃Loading Dataset</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "0beff5e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting project root: c:\\Users\\HP\\Desktop\\Healthcare_test_results_classification-\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Detect project root by going up until we find the 'src' directory\n",
    "current_dir = os.getcwd()\n",
    "while not os.path.isdir(os.path.join(current_dir, 'src')):\n",
    "    current_dir = os.path.dirname(current_dir)\n",
    "    if current_dir == os.path.dirname(current_dir):  # Reached filesystem root\n",
    "        raise FileNotFoundError(\"Could not find 'src' directory in any parent folders.\")\n",
    "\n",
    "# Set project root and add it to sys.path\n",
    "PROJECT_ROOT = current_dir\n",
    "print(f\"Setting project root: {PROJECT_ROOT}\")\n",
    "os.chdir(PROJECT_ROOT)\n",
    "sys.path.insert(0, PROJECT_ROOT)\n",
    "\n",
    "\n",
    "from src.data import loader, preprocessor\n",
    "from src.visualization import exploration_visualized\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "cd31d10b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Name</th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Blood Type</th>\n",
       "      <th>Medical Condition</th>\n",
       "      <th>Date of Admission</th>\n",
       "      <th>Doctor</th>\n",
       "      <th>Hospital</th>\n",
       "      <th>Insurance Provider</th>\n",
       "      <th>Billing Amount</th>\n",
       "      <th>Room Number</th>\n",
       "      <th>Admission Type</th>\n",
       "      <th>Discharge Date</th>\n",
       "      <th>Medication</th>\n",
       "      <th>Test Results</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Bobby JacksOn</td>\n",
       "      <td>27</td>\n",
       "      <td>Female</td>\n",
       "      <td>O-</td>\n",
       "      <td>Asthma</td>\n",
       "      <td>06/06/2022</td>\n",
       "      <td>Mark Hartman Jr.</td>\n",
       "      <td>Sons and Miller</td>\n",
       "      <td>Cigna</td>\n",
       "      <td>2625.980554</td>\n",
       "      <td>379</td>\n",
       "      <td>Elective</td>\n",
       "      <td>18/08/2022</td>\n",
       "      <td>Ibuprofen</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>LesLie TErRy</td>\n",
       "      <td>68</td>\n",
       "      <td>Female</td>\n",
       "      <td>O-</td>\n",
       "      <td>Cancer</td>\n",
       "      <td>19/11/2021</td>\n",
       "      <td>Angela Contreras</td>\n",
       "      <td>White-White</td>\n",
       "      <td>Cigna</td>\n",
       "      <td>1471.387317</td>\n",
       "      <td>113</td>\n",
       "      <td>Elective</td>\n",
       "      <td>20/11/2021</td>\n",
       "      <td>Ibuprofen</td>\n",
       "      <td>Inconclusive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>DaNnY sMitH</td>\n",
       "      <td>21</td>\n",
       "      <td>Female</td>\n",
       "      <td>A+</td>\n",
       "      <td>Hypertension</td>\n",
       "      <td>05/03/2022</td>\n",
       "      <td>David Ruiz</td>\n",
       "      <td>Group Middleton</td>\n",
       "      <td>Medicare</td>\n",
       "      <td>5131.488104</td>\n",
       "      <td>154</td>\n",
       "      <td>Emergency</td>\n",
       "      <td>16/05/2022</td>\n",
       "      <td>Paracetamol</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>andrEw waTtS</td>\n",
       "      <td>91</td>\n",
       "      <td>Male</td>\n",
       "      <td>AB-</td>\n",
       "      <td>Diabetes</td>\n",
       "      <td>06/04/2020</td>\n",
       "      <td>Jenny Griffith</td>\n",
       "      <td>Morris-Arellano</td>\n",
       "      <td>Blue Cross</td>\n",
       "      <td>8972.793157</td>\n",
       "      <td>293</td>\n",
       "      <td>Urgent</td>\n",
       "      <td>26/04/2020</td>\n",
       "      <td>Ibuprofen</td>\n",
       "      <td>Abnormal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>adrIENNE bEll</td>\n",
       "      <td>52</td>\n",
       "      <td>Female</td>\n",
       "      <td>A+</td>\n",
       "      <td>Diabetes</td>\n",
       "      <td>31/12/2022</td>\n",
       "      <td>Cynthia Scott</td>\n",
       "      <td>Williams-Davis</td>\n",
       "      <td>Blue Cross</td>\n",
       "      <td>2015.522684</td>\n",
       "      <td>265</td>\n",
       "      <td>Emergency</td>\n",
       "      <td>11/02/2023</td>\n",
       "      <td>Penicillin</td>\n",
       "      <td>Abnormal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID           Name  Age  Gender Blood Type Medical Condition  \\\n",
       "0   1  Bobby JacksOn   27  Female         O-            Asthma   \n",
       "1   2   LesLie TErRy   68  Female         O-            Cancer   \n",
       "2   3    DaNnY sMitH   21  Female         A+      Hypertension   \n",
       "3   4   andrEw waTtS   91    Male        AB-          Diabetes   \n",
       "4   5  adrIENNE bEll   52  Female         A+          Diabetes   \n",
       "\n",
       "  Date of Admission            Doctor         Hospital Insurance Provider  \\\n",
       "0        06/06/2022  Mark Hartman Jr.  Sons and Miller              Cigna   \n",
       "1        19/11/2021  Angela Contreras      White-White              Cigna   \n",
       "2        05/03/2022        David Ruiz  Group Middleton           Medicare   \n",
       "3        06/04/2020    Jenny Griffith  Morris-Arellano         Blue Cross   \n",
       "4        31/12/2022     Cynthia Scott   Williams-Davis         Blue Cross   \n",
       "\n",
       "   Billing Amount  Room Number Admission Type Discharge Date   Medication  \\\n",
       "0     2625.980554          379       Elective     18/08/2022    Ibuprofen   \n",
       "1     1471.387317          113       Elective     20/11/2021    Ibuprofen   \n",
       "2     5131.488104          154      Emergency     16/05/2022  Paracetamol   \n",
       "3     8972.793157          293         Urgent     26/04/2020    Ibuprofen   \n",
       "4     2015.522684          265      Emergency     11/02/2023   Penicillin   \n",
       "\n",
       "   Test Results  \n",
       "0        Normal  \n",
       "1  Inconclusive  \n",
       "2        Normal  \n",
       "3      Abnormal  \n",
       "4      Abnormal  "
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "project_root = r\"C:\\Users\\HP\\Desktop\\Healthcare_test_results_classification-\"  # Replace with the actual path\n",
    "data_path = os.path.join(project_root, 'data', 'raw')\n",
    "\n",
    "train_df, test_df = loader.load_data(\n",
    "    train_path=os.path.join(data_path, 'train data.csv'),\n",
    "    test_path=os.path.join(data_path, 'test data.csv')\n",
    ")\n",
    "\n",
    "train_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65df32b0",
   "metadata": {},
   "source": [
    "<h2>Handling DateTime Datatype</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "b51d32f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_date_features(df):\n",
    "    df = df.copy()\n",
    "    date_like_columns = []\n",
    "\n",
    "    for col in df.columns:\n",
    "        if df[col].dtype == 'object':\n",
    "            try:\n",
    "                # Try parsing with known consistent format first\n",
    "                converted = pd.to_datetime(df[col], format=\"%d/%m/%Y\", errors='raise')\n",
    "                df[col] = pd.to_datetime(df[col], format=\"%d/%m/%Y\", errors='coerce')\n",
    "                date_like_columns.append(col)\n",
    "              \n",
    "            except Exception:\n",
    "                continue  # Not a consistently date-formatted column\n",
    "\n",
    "    if not date_like_columns:\n",
    "        print(\"ℹ️ No date-like columns were found and converted.\")\n",
    "    else:\n",
    "        print(f\"\\n📅 Detected and converted date columns: {date_like_columns}\")\n",
    "    \n",
    "    # print(\"\\n📄 Preview of dataset after date conversion:\")\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "# fixed_datatypes=preprocessor.handle_date_features(train_df)\n",
    "# preprocessor.save_processed_df(fixed_datatypes,\"processed_train_data.csv\",output_dir=\"data/processed\")\n",
    "# fixed_datatypes.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f630b2f6",
   "metadata": {},
   "source": [
    "<h2>Handling Missing Values</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "df14a903",
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_missing_values(df):\n",
    "  \n",
    "    filled_info = []\n",
    "\n",
    "    for col in df.columns:\n",
    "        if df[col].isnull().any():\n",
    "            if df[col].dtype in ['float64', 'int64']:\n",
    "                median_val = df[col].median()\n",
    "                df[col] = df[col].fillna(median_val)\n",
    "                filled_info.append(f\"Filled numerical column '{col}' with median: {median_val}\")\n",
    "            else:\n",
    "                mode_val = df[col].mode().dropna()\n",
    "                if not mode_val.empty:\n",
    "                    mode_val = mode_val[0]\n",
    "                    df[col] = df[col].fillna(mode_val)\n",
    "\n",
    "                    filled_info.append(f\"Filled categorical column '{col}' with mode: {mode_val}\")\n",
    "                else:\n",
    "                    filled_info.append(f\"Could not fill column '{col}' — no valid mode found.\")\n",
    "\n",
    "    # Print summary\n",
    "    if filled_info:\n",
    "        print(\"\\n✅Missing values handled:\\n\" + \"\\n\".join(filled_info))\n",
    "    else:\n",
    "        print(\"❌No missing values found.\")\n",
    "\n",
    "    return df\n",
    "\n",
    "# handled_missing=preprocessor.handle_missing_values(fixed_datatypes)\n",
    "# preprocessor.save_processed_df(handled_missing,\"processed_train_data.csv\",output_dir=\"data/processed\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae749a21",
   "metadata": {},
   "source": [
    "<h2>Handling Negative Values</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "1904a442",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def Handle_Negative_Values(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = df.copy()\n",
    "    numeric_cols = df.select_dtypes(include='number').columns\n",
    "\n",
    "    for col in numeric_cols:\n",
    "        # Identify negative values\n",
    "        neg_mask = df[col] < 0\n",
    "\n",
    "        if neg_mask.any():\n",
    "            # Compute median of non-negative values\n",
    "            median_val = df.loc[~neg_mask, col].median()\n",
    "            \n",
    "            # Replace negative values with median\n",
    "            df.loc[neg_mask, col] = median_val\n",
    "            \n",
    "            print(f\"\\n🔄 Replaced {neg_mask.sum()} negative values in '{col}' with median: {median_val}\")\n",
    "\n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "352cd394",
   "metadata": {},
   "source": [
    "<h2>Encoding</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "7298dbdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoding_features(df: pd.DataFrame, max_unique_threshold=50) -> pd.DataFrame:\n",
    "    df = df.copy()\n",
    "\n",
    "    # Drop irrelevant columns\n",
    "    drop_cols = ['ID', 'Name', 'Room Number']\n",
    "    df.drop(columns=[col for col in drop_cols if col in df.columns], inplace=True)\n",
    "\n",
    "    # Handle binary categorical column: Gender\n",
    "    if 'Gender' in df.columns:\n",
    "        df = pd.get_dummies(df, columns=['Gender'], drop_first=True)\n",
    "        print(\"\\n✅ One-hot encoded 'Gender'.\")\n",
    "\n",
    "    # Label encode target: Test Results (ordinal in context of classification)\n",
    "    if 'Test Results' in df.columns:\n",
    "        df['Test Results'] = df['Test Results'].map({\n",
    "            'Normal': 0, 'Abnormal': 1, 'Inconclusive': 2\n",
    "        })\n",
    "        print(\"🎯 Label encoded target column 'Test Results'.\")\n",
    "\n",
    "    # Detect remaining categorical columns\n",
    "    categorical_cols = df.select_dtypes(include='object').columns.tolist()\n",
    "    categorical_cols = [col for col in categorical_cols if col != 'Test Results']\n",
    "\n",
    "    # Separate based on cardinality\n",
    "    low_cardinality_cols = [col for col in categorical_cols if df[col].nunique() <= max_unique_threshold]\n",
    "    high_cardinality_cols = [col for col in categorical_cols if df[col].nunique() > max_unique_threshold]\n",
    "\n",
    "    # One-hot encode low-cardinality columns\n",
    "    if low_cardinality_cols:\n",
    "        df = pd.get_dummies(df, columns=low_cardinality_cols, drop_first=True)\n",
    "        for col in low_cardinality_cols:\n",
    "            print(f\"✅ One-hot encoded '{col}'.\")\n",
    "\n",
    "    # Frequency encode high-cardinality columns\n",
    "    for col in high_cardinality_cols:\n",
    "        freq_map = df[col].value_counts()\n",
    "        df[col] = df[col].map(freq_map)\n",
    "        print(f\"✅ Frequency encoded '{col}'.\")\n",
    "\n",
    "    print(f\"\\n📐 Encoded shape: {df.shape}\")\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "# encoded_df = preprocessor.encode_students_dataset(train_df)\n",
    "# print(\"Encoded shape:\", encoded_df.shape)\n",
    "# encoded_df=preprocessor.encoding_features(handled_missing)\n",
    "\n",
    "# encoded_df = preprocessor.encoding_features(encoded_df)\n",
    "# preprocessor.save_processed_df(encoded_df, \"processed_train_data.csv\", output_dir=\"data/processed\")\n",
    "\n",
    "# encoded_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5f73f2e",
   "metadata": {},
   "source": [
    "<h2>Scaling (Standrization)</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d02ad17",
   "metadata": {},
   "source": [
    "\n",
    "PCA, Logistic Regression, SVM, MLP → Use StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "30587a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_numerical_features(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = df.copy()\n",
    "\n",
    "    # Define known numerical features\n",
    "    numeric_cols = ['Age', 'Billing Amount']\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    df[numeric_cols] = scaler.fit_transform(df[numeric_cols])\n",
    "\n",
    "    print(f\"\\n✅ Scaled numerical columns: {numeric_cols}\")\n",
    "    \n",
    "    print(f\"\\n📐 Scaled shape: {df.shape}\")\n",
    "    # print(f\"\\n📄 Preview of scaled dataset:\")\n",
    "\n",
    "    return df\n",
    "\n",
    "#  scaled_df=preprocessor.scale_numerical_features(encoded_df)\n",
    "\n",
    "#  preprocessor.save_processed_df(scaled_df,\"processed_train_data.csv\",output_dir=\"data/processed\")\n",
    "#  scaled_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "874456a9",
   "metadata": {},
   "source": [
    "<h2>Preprocessing Pipeline</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "f23db7e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📅 Detected and converted date columns: ['Date of Admission', 'Discharge Date']\n",
      "\n",
      "✅Missing values handled:\n",
      "Filled categorical column 'Blood Type' with mode: B-\n",
      "Filled categorical column 'Doctor' with mode: Angela Contreras\n",
      "Filled categorical column 'Hospital' with mode: Houston PLC\n",
      "Filled categorical column 'Insurance Provider' with mode: Blue Cross\n",
      "Filled numerical column 'Billing Amount' with median: 5313.5078885\n",
      "Filled categorical column 'Admission Type' with mode: Urgent\n",
      "\n",
      "🔄 Replaced 247 negative values in 'Billing Amount' with median: 5313.5078885\n",
      "\n",
      "✅ One-hot encoded 'Gender'.\n",
      "🎯 Label encoded target column 'Test Results'.\n",
      "✅ One-hot encoded 'Blood Type'.\n",
      "✅ One-hot encoded 'Medical Condition'.\n",
      "✅ One-hot encoded 'Insurance Provider'.\n",
      "✅ One-hot encoded 'Admission Type'.\n",
      "✅ One-hot encoded 'Medication'.\n",
      "✅ Frequency encoded 'Doctor'.\n",
      "✅ Frequency encoded 'Hospital'.\n",
      "\n",
      "📐 Encoded shape: (50000, 30)\n",
      "\n",
      "✅ Scaled numerical columns: ['Age', 'Billing Amount']\n",
      "\n",
      "📐 Scaled shape: (50000, 30)\n",
      "✅ Saved processed DataFrame to:\n",
      "c:\\Users\\HP\\Desktop\\Healthcare_test_results_classification-\\data\\processed\\processed_train_data.csv\n",
      "✅ Processed data saved to data/processed/processed_train_data.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Date of Admission</th>\n",
       "      <th>Doctor</th>\n",
       "      <th>Hospital</th>\n",
       "      <th>Billing Amount</th>\n",
       "      <th>Discharge Date</th>\n",
       "      <th>Test Results</th>\n",
       "      <th>Gender_Male</th>\n",
       "      <th>Blood Type_A-</th>\n",
       "      <th>Blood Type_AB+</th>\n",
       "      <th>...</th>\n",
       "      <th>Insurance Provider_Blue Cross</th>\n",
       "      <th>Insurance Provider_Cigna</th>\n",
       "      <th>Insurance Provider_Medicare</th>\n",
       "      <th>Insurance Provider_UnitedHealthcare</th>\n",
       "      <th>Admission Type_Emergency</th>\n",
       "      <th>Admission Type_Urgent</th>\n",
       "      <th>Medication_Ibuprofen</th>\n",
       "      <th>Medication_Lipitor</th>\n",
       "      <th>Medication_Paracetamol</th>\n",
       "      <th>Medication_Penicillin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.772600</td>\n",
       "      <td>2022-06-06</td>\n",
       "      <td>528</td>\n",
       "      <td>1350</td>\n",
       "      <td>-0.877417</td>\n",
       "      <td>2022-08-18</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.906636</td>\n",
       "      <td>2021-11-19</td>\n",
       "      <td>1389</td>\n",
       "      <td>2108</td>\n",
       "      <td>-1.239366</td>\n",
       "      <td>2021-11-20</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.018342</td>\n",
       "      <td>2022-03-05</td>\n",
       "      <td>349</td>\n",
       "      <td>1561</td>\n",
       "      <td>-0.091974</td>\n",
       "      <td>2022-05-16</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.848646</td>\n",
       "      <td>2020-04-06</td>\n",
       "      <td>66</td>\n",
       "      <td>1423</td>\n",
       "      <td>1.112222</td>\n",
       "      <td>2020-04-26</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.251324</td>\n",
       "      <td>2022-12-31</td>\n",
       "      <td>360</td>\n",
       "      <td>1350</td>\n",
       "      <td>-1.068787</td>\n",
       "      <td>2023-02-11</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Age Date of Admission  Doctor  Hospital  Billing Amount  \\\n",
       "0 -0.772600        2022-06-06     528      1350       -0.877417   \n",
       "1  0.906636        2021-11-19    1389      2108       -1.239366   \n",
       "2 -1.018342        2022-03-05     349      1561       -0.091974   \n",
       "3  1.848646        2020-04-06      66      1423        1.112222   \n",
       "4  0.251324        2022-12-31     360      1350       -1.068787   \n",
       "\n",
       "  Discharge Date  Test Results  Gender_Male  Blood Type_A-  Blood Type_AB+  \\\n",
       "0     2022-08-18             0        False          False           False   \n",
       "1     2021-11-20             2        False          False           False   \n",
       "2     2022-05-16             0        False          False           False   \n",
       "3     2020-04-26             1         True          False           False   \n",
       "4     2023-02-11             1        False          False           False   \n",
       "\n",
       "   ...  Insurance Provider_Blue Cross  Insurance Provider_Cigna  \\\n",
       "0  ...                          False                      True   \n",
       "1  ...                          False                      True   \n",
       "2  ...                          False                     False   \n",
       "3  ...                           True                     False   \n",
       "4  ...                           True                     False   \n",
       "\n",
       "   Insurance Provider_Medicare  Insurance Provider_UnitedHealthcare  \\\n",
       "0                        False                                False   \n",
       "1                        False                                False   \n",
       "2                         True                                False   \n",
       "3                        False                                False   \n",
       "4                        False                                False   \n",
       "\n",
       "   Admission Type_Emergency  Admission Type_Urgent  Medication_Ibuprofen  \\\n",
       "0                     False                  False                  True   \n",
       "1                     False                  False                  True   \n",
       "2                      True                  False                 False   \n",
       "3                     False                   True                  True   \n",
       "4                      True                  False                 False   \n",
       "\n",
       "   Medication_Lipitor  Medication_Paracetamol  Medication_Penicillin  \n",
       "0               False                   False                  False  \n",
       "1               False                   False                  False  \n",
       "2               False                    True                  False  \n",
       "3               False                   False                  False  \n",
       "4               False                   False                   True  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "def process_and_save_data(train_df, outputpath=\"data/processed/\"):\n",
    "    os.makedirs(outputpath, exist_ok=True)\n",
    "\n",
    "    # Step-by-step preprocessing\n",
    "    handled_dates = handle_date_features(train_df)\n",
    "    handled_missing_values = handle_missing_values(handled_dates)\n",
    "    handled_negatives = Handle_Negative_Values(handled_missing_values)\n",
    "    encoded_data = encoding_features(handled_negatives)\n",
    "    scaled_data = scale_numerical_features(encoded_data)\n",
    "\n",
    "    # Save and return\n",
    "    preprocessor.save_processed_df(scaled_data, \"processed_train_data.csv\", output_dir=outputpath)\n",
    "    print(f\"✅ Processed data saved to {outputpath}processed_train_data.csv\")\n",
    "   \n",
    "    return scaled_data\n",
    "\n",
    "# Call it\n",
    "processed_train_df = process_and_save_data(train_df, outputpath=\"data/processed/\")\n",
    "processed_train_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4ddc0db",
   "metadata": {},
   "source": [
    "<h2>Old Pipeline</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fa1dd45",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# class DateFeatureHandler(BaseEstimator, TransformerMixin):\n",
    "#     def fit(self, X, y=None): return self\n",
    "#     def transform(self, X): return preprocessor.handle_date_features(X)\n",
    "\n",
    "# class MissingValueImputer(BaseEstimator, TransformerMixin):\n",
    "#     def fit(self, X, y=None): return self\n",
    "#     def transform(self, X): return preprocessor.handle_missing_values(X)\n",
    "\n",
    "# class FeatureEncoder(BaseEstimator, TransformerMixin):\n",
    "#     def fit(self, X, y=None): return self\n",
    "#     def transform(self, X): return preprocessor.encoding_features(X)\n",
    "\n",
    "\n",
    "# class FeatureScaler(BaseEstimator, TransformerMixin):\n",
    "#     def fit(self, X, y=None): return self\n",
    "#     def transform(self, X): return preprocessor.scale_numerical_features(X)\n",
    "\n",
    "\n",
    "# preprocessing_pipeline = Pipeline([\n",
    "#     ('imputer', MissingValueImputer()),\n",
    "#     ('date_handler', DateFeatureHandler()),\n",
    "#     ('encoder', FeatureEncoder()),\n",
    "#     ('scaler', FeatureScaler())\n",
    "# ])\n",
    "\n",
    "# processed_df = preprocessing_pipeline.fit_transform(train_df)\n",
    "\n",
    "# preprocessor.save_processed_df(processed_df, filename=\"preprocessed_train_data.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f09034d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7e6c6d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec0604e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14edf573",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54af7a96",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "842cbe35",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "027c0066",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
